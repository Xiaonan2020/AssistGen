{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Deepseek企业级Agent项目开发实战</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Part 3. Ollama REST API - api/chat 接口详解 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Ollama 服务启动后会提供一系列原生 ` REST API` 端点。通过这些`Endpoints`可以在代码环境下与`ollama`启动的大模型进行交互、管理模型和获取相关信息。其中两个`endpoint` 是最重要的，分别是：\n",
    "  - <font color=\"red\">**POST /api/generate**</font>\n",
    "  - <font color=\"red\">**POST /api/chat**</font>\n",
    "\n",
    "&emsp;&emsp;其他端点情况：\n",
    "  - POST /api/create   \n",
    "  - POST /api/tags\n",
    "  - POST /api/show\n",
    "  - POST /api/copy\n",
    "  - DELETE /api/delete\n",
    "  - POST /api/pull\n",
    "  - POST /api/push\n",
    "  - POST /api/embed\n",
    "  - GET /api/ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. /api/chat 接口参数概览\n",
    "\n",
    "&emsp;&emsp;该接口使用提供的模型在聊天中生成下一条消息。与 `/api/generate` 的参数基本一致，但是在请求的参数上会根据聊天场景进行调整。主要调整的是：\n",
    "- 不再使用 `prompt` 参数，而是使用 `messages` 参数。\n",
    "- 新增了 `tools` 参数，用于支持工具调用。\n",
    "\n",
    "&emsp;&emsp;其可以使用的具体参数如下所示，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    ".center \n",
    "{\n",
    "  width: auto;\n",
    "  display: table;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<p align=\"center\"><font face=\"黑体\" size=4>常规参数</font></p>\n",
    "<div class=\"center\">\n",
    "\n",
    "| 参数名       | 类型      | 描述                                                         |\n",
    "| ------------ | --------- | ------------------------------------------------------------ |\n",
    "| **model**    | *(必需)*  | 模型名称。                                                   |\n",
    "| <font color=\"red\">**messages**</font> | *(必需)*  | 聊天的消息，用于保持聊天记忆。                               |\n",
    "| <font color=\"red\">**tools**</font>    | *(可选)*  | JSON 中的工具列表，供模型使用（如果支持）。                 |\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "<p align=\"center\"><font face=\"黑体\" size=4>消息对象字段</font></p>\n",
    "<div class=\"center\">\n",
    "\n",
    "| 字段名       | 描述                                                         |\n",
    "| ------------ | ------------------------------------------------------------ |\n",
    "| <font color=\"red\">**role**</font>     | 消息的角色，可以是 `system`、`user`、`assistant` 或 `tool`。 |\n",
    "| <font color=\"red\">**content**</font>  | 消息的内容。                                                 |\n",
    "| **images**   | *(可选)* 要在消息中包含的图像列表（适用于多模态模型，如 llava）。 |\n",
    "| **tool_calls** | *(可选)* 模型希望使用的 JSON 中的工具列表。               |\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "<p align=\"center\"><font face=\"黑体\" size=4>高级参数 (可选)</font></p>\n",
    "<div class=\"center\">\n",
    "\n",
    "| 参数名       | 描述                                                         |\n",
    "| ------------ | ------------------------------------------------------------ |\n",
    "| **format**   | 返回响应的格式。格式可以是 `json` 或 JSON 模式。            |\n",
    "| <font color=\"red\">**options**</font>  | 文档中列出的其他模型参数，例如 `temperature`。              |\n",
    "| **stream**   | 如果为 `false`，响应将作为单个响应对象返回，而不是对象流。  |\n",
    "| <font color=\"red\">**keep_alive**</font> | 控制模型在请求后保持加载的时间（默认：5分钟）。           |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，Options参数说明：\n",
    "\n",
    "| 参数名 | 描述 | 值类型 | 示例用法 |\n",
    "| --------------- | ------------------------------------------------------------ | ------ | ---------------------- |\n",
    "| mirostat | 启用 Mirostat 采样以控制困惑度。（默认：0，0 = 禁用，1 = Mirostat，2 = Mirostat 2.0） | int | mirostat 0 |\n",
    "| mirostat_eta| 影响算法对生成文本反馈的响应速度。较低的学习率会导致调整较慢，而较高的学习率会使算法更具响应性。（默认：0.1） | float | mirostat_eta 0.1 |\n",
    "| mirostat_tau| 控制输出的连贯性和多样性之间的平衡。较低的值会导致更集中和连贯的文本。（默认：5.0） | float | mirostat_tau 5.0 |\n",
    "| <font color=\"red\">num_ctx</font> | 设置用于生成下一个标记的上下文窗口大小。（默认：2048）, 影响的是模型可以一次记住的最大 token 数量。 | int | num_ctx 4096|\n",
    "| repeat_last_n| 设置模型回溯的范围以防止重复。（默认：64，0 = 禁用，-1 = num_ctx） | int | repeat_last_n 64 |\n",
    "| repeat_penalty| 设置惩罚重复的强度。较高的值（例如 1.5）会更强烈地惩罚重复，而较低的值（例如 0.9）会更宽松。（默认：1.1） | float | repeat_penalty 1.1 |\n",
    "| <font color=\"red\">temperature</font> | 模型的温度。增加温度会使模型的回答更具创造性。（默认：0.8） | float | temperature 0.7 |\n",
    "| seed | 设置用于生成的随机数种子。将其设置为特定数字将使模型对相同提示生成相同的文本。（默认：0） | int | seed 42 |\n",
    "| <font color=\"red\">stop</font> | 设置使用的停止序列。当遇到此模式时，LLM 将停止生成文本并返回。可以通过在 modelfile 中指定多个单独的停止参数来设置多个停止模式。 | string | stop \"AI assistant:\" |\n",
    "| <font color=\"red\">num_predict</font> | 生成文本时要预测的最大标记数。（默认：-1，无限生成）,影响模型最大可以生成的 token 数量。 | int | num_predict 42 |\n",
    "| top_k | 降低生成无意义文本的概率。较高的值（例如 100）会给出更多样化的答案，而较低的值（例如 10）会更保守。（默认：40） | int | top_k 40 |\n",
    "| top_p | 与 top-k 一起工作。较高的值（例如 0.95）会导致更具多样性的文本，而较低的值（例如 0.5）会生成更集中和保守的文本。（默认：0.9） | float | top_p 0.9 |\n",
    "| min_p | top_p 的替代方案，旨在确保质量和多样性之间的平衡。参数 p 表示考虑标记的最小概率，相对于最可能标记的概率。例如，p=0.05 时，最可能的标记概率为 0.9，值小于 0.045 的 logits 会被过滤掉。（默认：0.0） | float | min_p 0.05 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. requests 调用方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp; `/api/chat` 依然还是可以`requests`库进行调用。如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成响应: {\n",
      "  \"model\": \"deepseek-r1:1.5b\",\n",
      "  \"created_at\": \"2025-08-10T15:50:17.814845Z\",\n",
      "  \"message\": {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"<think>\\n嗯，用户让我生成一个关于人工智能的简短介绍。首先，我需要确定这个介绍应该涵盖哪些主要方面。人工智能现在是一个非常热门的话题，涉及到技术、应用、未来展望等方面。\\n\\n我应该从定义开始，说明人工智能是什么，它涉及机器学习、深度学习这些现代技术。然后提到它对社会和经济的影响，比如效率提升、个性化服务的提供等。接下来，可以描述一些具体的应用领域，如医疗、金融、教育和制造业，说明它们各自的特点和成就。\\n\\n同时，需要强调AI面临的挑战和未来的机遇，这样可以让介绍更有深度，也更全面。最后，简要提到技术进步带来的变革，让读者明白人工智能的发展趋势。\\n\\n另外，用户可能希望这个介绍既专业又易于理解，所以用词不能太复杂，但也要准确。结构上可以分成几个部分：定义、影响、应用、挑战和未来展望，这样逻辑清晰。\\n\\n现在，我得把这些点组织起来，确保信息全面且简洁。比如，在定义里提到机器学习、深度学习，然后在影响部分强调效率提升、个性化服务、自动化处理等。应用部分可以详细说明医疗诊断的精准化、金融投资的风险评估、教育个性化教学和制造业高精度制造。\\n\\n挑战方面，应该包括数据隐私、算法偏见以及伦理问题。最后，展望未来，AI可能成为人类社会的基石，推动创新和社会进步。\\n\\n总的来说，这个简短介绍需要涵盖人工智能的基本概念、应用和影响，同时提到面临的挑战，并展望其未来前景。这样既全面又不失简洁，能够有效地传达人工智能的重要性和潜力。\\n</think>\\n\\n人工智能（Artificial Intelligence, AI）是当前备受关注的人类智能化领域，它通过机器学习（Machine Learning）、深度学习（Deep Learning）等技术模拟人类的思维和认知能力，广泛应用于各个领域。\\n\\n人工智能推动了社会的进步、经济的增长和生活质量的提升。从医疗诊断到金融投资，从教育到制造业，AI为 humans 和 machines 的互动创造了前所未有的机遇。然而，AI也面临着数据隐私、算法偏见、伦理问题等挑战，这些都要求人类保持清醒地思考 AI 的应用方向。\\n\\n未来，人工智能可能会成为人类社会的重要基石，推动创新、社会治理和可持续发展。尽管需要解决诸多技术难题，但随着技术进步和社会需求的持续增长，人工智能将继续引领人类文明前行。\"\n",
      "  },\n",
      "  \"done_reason\": \"stop\",\n",
      "  \"done\": true,\n",
      "  \"total_duration\": 5617516700,\n",
      "  \"load_duration\": 38669900,\n",
      "  \"prompt_eval_count\": 13,\n",
      "  \"prompt_eval_duration\": 138192000,\n",
      "  \"eval_count\": 491,\n",
      "  \"eval_duration\": 5439565000\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# 设置 API 端点\n",
    "chat_url = \"http://127.0.0.1:11434/api/chat\"    # 这里需要根据实际情况进行修改\n",
    "\n",
    "# 示例数据\n",
    "chat_payload = {\n",
    "    \"model\": \"deepseek-r1:1.5b\",   # 这里需要根据实际情况进行修改\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",  # 消息角色，用户发送的消息\n",
    "            \"content\": \"请生成一个关于人工智能的简短介绍。\"  # 用户的消息内容\n",
    "        }\n",
    "    ],\n",
    "    \"tools\": [],  # 如果有工具可以在这里添加\n",
    "    \"stream\": False,  # 默认使用的是True，如果设置为False，则返回的是一个完整的响应，而不是一个流式响应\n",
    "}\n",
    "\n",
    "# 调用聊天接口\n",
    "response_chat = requests.post(chat_url, json=chat_payload)\n",
    "if response_chat.status_code == 200:\n",
    "    chat_response = response_chat.json()\n",
    "    print(\"生成响应:\", json.dumps(chat_response, ensure_ascii=False, indent=2))\n",
    "else:\n",
    "    print(\"生成请求失败:\", response_chat.status_code, response_chat.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;返回的响应中包含以下参数，其对应的描述如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    ".center \n",
    "{\n",
    "  width: auto;\n",
    "  display: table;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<p align=\"center\"><font face=\"黑体\" size=4>响应参数</font></p>\n",
    "<div class=\"center\">\n",
    "\n",
    "| 参数名                  | 描述                                                         |\n",
    "| ----------------------- | ------------------------------------------------------------ |\n",
    "| **total_duration**      | 单次响应花费的总时间                                          |\n",
    "| **load_duration**       | 加载模型花费的时间                                   |\n",
    "| **prompt_eval_count**   | 提示中的token数                                               |\n",
    "| **prompt_eval_duration**| 评估提示所花费的时间（以纳秒为单位）                                 |\n",
    "| **eval_count**          | 响应中的token数                                               |\n",
    "| **eval_duration**       | 生成响应的时间（以纳秒为单位）                              |\n",
    "| **context**             | 在此响应中使用的对话的编码，可以在下一个请求中发送以保持对话记忆 |\n",
    "| **response**            | 空响应是流的，如果未流式传输，则将包含完整的响应             |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;重点关注以下几个参数："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=\"red\">**message**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在 `/chat` 接口中，返回的模型响应结果存放在 `message` 中， 同样对于 `DeepSeek-R1` 模型，`response` 字段中包含<think> 标签和正常文本，<think> 标签用于表示模型的思考过程或内部推理，而正常的文本则是模型生成的实际输出内容。注意：非推理类模型的返回结果中没有<think></think>标识。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\n好，我现在需要帮用户生成一个关于人工智能的简短介绍。首先，我得理解用户的需求是什么。他们可能对AI不太了解，想要一个简洁明了的概述。\\n\\n我应该从基础开始讲起，比如定义。人工智能是模拟人类智能的技术，这点很重要。然后，我可以提到主要应用领域，比如机器学习、自然语言处理和计算机视觉，这样可以让介绍更有针对性。\\n\\n接下来，我需要说明AI的应用范围，比如在医疗、金融和交通中的作用，这样用户能明白它的实际价值。同时，也不能忽视伦理和社会影响，这部分也是大家关心的点。\\n\\n还要提到当前的发展阶段，强调它是一个快速发展的领域，这样能展示出未来的潜力。最后，保持整体内容简明扼要，适合快速阅读。\\n\\n可能用户需要这个介绍用于学习、演讲或者作为参考资料。所以信息要准确，结构清晰，重点突出。我要确保涵盖主要方面，同时不显得冗长。这样用户就能得到一个全面又简洁的人工智能简介了。\\n</think>\\n\\n人工智能（Artificial Intelligence, AI）是指通过模拟人类智能的技术，使计算机系统能够执行如学习、推理、问题解决和自然语言处理等任务。AI技术广泛应用于医疗、金融、交通等领域，帮助提高效率并解决复杂问题。随着算法的进步和数据的增加，人工智能正逐步改变我们的生活方式和社会结构。'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response[\"message\"]['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;可以通过简单的字符串操作来分离 <think> 标签中的思考内容和正常的文本内容，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "思考内容:\n",
      " 好，我现在需要帮用户生成一个关于人工智能的简短介绍。首先，我得理解用户的需求是什么。他们可能对AI不太了解，想要一个简洁明了的概述。\n",
      "\n",
      "我应该从基础开始讲起，比如定义。人工智能是模拟人类智能的技术，这点很重要。然后，我可以提到主要应用领域，比如机器学习、自然语言处理和计算机视觉，这样可以让介绍更有针对性。\n",
      "\n",
      "接下来，我需要说明AI的应用范围，比如在医疗、金融和交通中的作用，这样用户能明白它的实际价值。同时，也不能忽视伦理和社会影响，这部分也是大家关心的点。\n",
      "\n",
      "还要提到当前的发展阶段，强调它是一个快速发展的领域，这样能展示出未来的潜力。最后，保持整体内容简明扼要，适合快速阅读。\n",
      "\n",
      "可能用户需要这个介绍用于学习、演讲或者作为参考资料。所以信息要准确，结构清晰，重点突出。我要确保涵盖主要方面，同时不显得冗长。这样用户就能得到一个全面又简洁的人工智能简介了。\n",
      "\n",
      "正常内容:\n",
      " 人工智能（Artificial Intelligence, AI）是指通过模拟人类智能的技术，使计算机系统能够执行如学习、推理、问题解决和自然语言处理等任务。AI技术广泛应用于医疗、金融、交通等领域，帮助提高效率并解决复杂问题。随着算法的进步和数据的增加，人工智能正逐步改变我们的生活方式和社会结构。\n"
     ]
    }
   ],
   "source": [
    "# 提取 <think> 标签中的内容\n",
    "think_start = chat_response[\"message\"]['content'].find(\"<think>\")\n",
    "think_end = chat_response[\"message\"]['content'].find(\"</think>\")\n",
    "\n",
    "if think_start != -1 and think_end != -1:\n",
    "    think_content = chat_response[\"message\"]['content'][think_start + len(\"<think>\"):think_end].strip()\n",
    "else:\n",
    "    think_content = \"No think content found.\"\n",
    "\n",
    "# 提取正常的文本内容\n",
    "normal_content = chat_response[\"message\"]['content'][think_end + len(\"</think>\"):].strip()\n",
    "\n",
    "# 打印结果\n",
    "print(\"思考内容:\\n\", think_content)\n",
    "print(\"\\n正常内容:\\n\", normal_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;其他的重点参数和 `/generation` 参数使用方法也保持一致，示例代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成响应: {\n",
      "  \"model\": \"deepseek-r1:32b\",\n",
      "  \"created_at\": \"2025-02-13T11:22:03.848936446Z\",\n",
      "  \"message\": {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"<think>\\n好的，用户让我生成一个关于人工智能的简短介绍。首先，我得理解用户的需求是什么。可能是一个学生在做作业，或者是一个职场人士需要快速了解AI的基本概念。\\n\\n接下来，我应该考虑内容的结构。通常，一个好的简介应该包括定义、关键点和应用领域。这样可以让读者全面了解主题。\\n\\n然后，思考如何用简单明了的语言解释人工智能，避免太专业的术语，但又要准确。可能还要提到机器学习和深度学习这些核心技术，因为它们是AI的重要组成部分。\\n\\n再考虑应用场景，比如医疗、金融和交通等，这样可以展示AI的实际影响。最后，加入一些关于伦理和社会影响的内容，让介绍更全面。\\n\\n现在，把这些点组织成一个连贯的段落，确保逻辑清晰，语言流畅。同时要注意字数控制在简短范围内，大概200字左右。\\n</think>\\n\\n人工智能（Artificial Intelligence, AI）是模拟人类智能的系统或机器，通过学习、推理和自主决策来执行任务。它涵盖多个领域，如机器学习、自然语言处理和计算机视觉，广泛应用于医疗、金融、交通等。AI不仅提高效率，还推动社会进步，但也引发伦理和社会挑战。\"\n",
      "  },\n",
      "  \"done_reason\": \"stop\",\n",
      "  \"done\": true,\n",
      "  \"total_duration\": 8531725124,\n",
      "  \"load_duration\": 62273516,\n",
      "  \"prompt_eval_count\": 13,\n",
      "  \"prompt_eval_duration\": 87000000,\n",
      "  \"eval_count\": 254,\n",
      "  \"eval_duration\": 8380000000\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests # type: ignore\n",
    "import json\n",
    "\n",
    "# 设置 API 端点\n",
    "chat_url = \"http://192.168.110.131:11434/api/chat\"    # 这里需要根据实际情况进行修改\n",
    "\n",
    "# 示例数据\n",
    "chat_payload = {\n",
    "    \"model\": \"deepseek-r1:32b\",   # 这里需要根据实际情况进行修改\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",  # 消息角色，用户发送的消息\n",
    "            \"content\": \"请生成一个关于人工智能的简短介绍。\"  # 用户的消息内容\n",
    "        }\n",
    "    ],\n",
    "    \"tools\": [],  # 如果有工具可以在这里添加\n",
    "    \"stream\": False,  # 默认使用的是True，如果设置为False，则返回的是一个完整的响应，而不是一个流式响应\n",
    "    \"keep_alive\": \"10m\",   # 设置模型在请求后保持加载的时间\n",
    "    \"options\":{\n",
    "        \"temperature\": 0.7,   \n",
    "        \"num_ctx\":2048,\n",
    "        \"num_predict\": 4096,\n",
    "    }\n",
    "}\n",
    "\n",
    "# 调用聊天接口\n",
    "response_chat = requests.post(chat_url, json=chat_payload)\n",
    "if response_chat.status_code == 200:\n",
    "    chat_response = response_chat.json()\n",
    "    print(\"生成响应:\", json.dumps(chat_response, ensure_ascii=False, indent=2))\n",
    "else:\n",
    "    print(\"生成请求失败:\", response_chat.status_code, response_chat.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;流式输出代码也要针对`/chat`接口的返回响应格式做略微的修改："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "好的，我现在需要帮用户生成一个关于人工智能的简短介绍。首先，我得理解用户的需求是什么。看起来他们可能对AI不太了解，所以需要一个简洁明了的解释。\n",
      "\n",
      "接下来，我要考虑涵盖哪些关键点。人工智能的基本定义是必须有的，比如它是模拟人类智能的技术。然后，可以提到一些主要的应用领域，比如机器学习、自然语言处理和计算机视觉，这样可以让内容更具体。\n",
      "\n",
      "我还需要强调AI的发展对社会的影响，比如在医疗、教育和交通等方面带来的变化，以及它如何改变我们的生活方式。不过，也要提醒用户注意伦理和社会问题，这显示了全面性。\n",
      "\n",
      "最后，结构要清晰，每句话简洁有力，避免使用专业术语过多，让不同背景的读者都能理解。同时，控制在50字左右，确保信息精炼。\n",
      "</think>\n",
      "\n",
      "人工智能（Artificial Intelligence, AI）是模拟人类智能的技术，通过机器学习、自然语言处理和计算机视觉等方法，使计算机能够执行复杂任务。AI正广泛应用于医疗、教育、交通等领域，推动社会进步，但也需关注伦理和社会影响。"
     ]
    }
   ],
   "source": [
    "import requests  # type: ignore\n",
    "import json\n",
    "\n",
    "# 设置 API 端点\n",
    "generate_url = \"http://192.168.110.131:11434/api/generate\"\n",
    "\n",
    "# 示例数据\n",
    "generate_payload = {\n",
    "    \"model\": \"deepseek-r1:32b\",\n",
    "    \"prompt\": \"请生成一个关于人工智能的简短介绍。\",\n",
    "    \"stream\": True,  # 启用流式输出\n",
    "    \"options\": {\n",
    "        \"temperature\": 0.6,\n",
    "        \"keep_alive\": \"10m\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# 调用生成接口\n",
    "with requests.post(generate_url, json=generate_payload, stream=True) as response_generate:\n",
    "    if response_generate.status_code == 200:\n",
    "        # 逐行读取流式响应\n",
    "        for line in response_generate.iter_lines():\n",
    "            if line:  # 确保行不为空\n",
    "                # 解析 JSON 响应\n",
    "                generate_response = json.loads(line)\n",
    "                \n",
    "                # 提取并打印 response 字段\n",
    "                if \"response\" in generate_response:\n",
    "                    print(generate_response[\"response\"], end='')  # end='' 防止换行\n",
    "                if generate_response.get(\"done\", False):\n",
    "                    break  # 如果 done 为 True，结束循环\n",
    "    else:\n",
    "        print(\"生成请求失败:\", response_generate.status_code, response_generate.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
